element_a<-fir_list[1]
element_a
element_a<-fir_list[[1]]
element_a
element_a<-fir_list[1]
element_a
class(element_a)
element_b<-fir_list[2]
element_b
class(element_b)
class(element_b)
element_b<-fir_list[[2]]
class(element_b)
element_b<-fir_list["b"] #[[]]를 쓰니까 해당요소의 데이터 속성이 출력됨 []하면
class(element_b)
#[]는 단일 대괄호 연산자로 리스트의 부분을 추출하는데 사용
#[[]]은 리스트의 요소를 반환하고 []은 리스트를 반환
part <- fir_list[c(1,3)]
part
#list객체
#list객체는 유형과 크기가 다른 객체를 저장할 수 있기 때문에 가장 일반젃인 저장소임
fir_list <- list(a=c(1,2,3,4,5),
b=matrix(1:10, nrow = 2, ncol = 5 ),
c=data.frame(price=c(57.4,79.4,11.8),
stock=c("MOT","IBM","CSCO")))
#[]는 단일 대괄호 연산자로 리스트의 부분을 추출하는데 사용
#[[]]은 리스트의 요소를 반환하고 []은 리스트를 반환
part <- fir_list[c(1,3)]
part #a,c만 출력
#[[]](이중 대괄호) 연산자를 쓰니까 해당요소의 데이터 속성이 출력됨
#[]하면 상위 데이터 구조의 속성이 출력됨
element_b<-fir_list[["b"]]
class(element_b)
#[[]](이중 대괄호) 연산자를 쓰니까 해당요소의 데이터 속성이 출력됨
#[]하면 상위 데이터 구조의 속성이 출력됨
element_b<-fir_list[["b"]]
class(part)
length_part <- length(part)
length_part
en
#new.env()
#인바이런먼트는 성능을 높히기 위해 R 내부적으로 많이 사용하는 구조임
#참조 의미론(reference smetic)을 가짐
#참조 의미론: 변수가 객체를 값으로 저장하지 않지만 메모리 사에 위치한 객체의 주소를 저장함 크기가 큰 객체가 사용될 때마다 복사의 필요가 없기에 효율적인 코드가 가능
#인바이런먼트는 주로 룩업성능의 해시지도를 실행하는데 사용함
en<-new.env()
en[["first"]]<- 5
en[["second"]]<- 6
en$third<-7
en
ls(env)
ls(env)
ls(en)
install.packages(c('rzmq','repr','IRkernel','IRdisplay'), repos = 'http://irkernel.github.io/', type = 'source')
install.packages(c('rzmq','repr','IRkernel','IRdisplay'), repos = 'http://irkernel.github.io/', type = 'source')
install.packages(c('repr', 'IRdisplay', 'IRkernel'), type = 'source')
IRkernel::installspec()
IRkernel::installspec()
IRkernel::installspec()
install.packages("IRkernel")
IRkernel::installspec()
IRkernel::installspec(user=FALSE)
source('~/.active-rstudio-document', echo=TRUE)
source('C:/Users/STUDENT/Desktop/비대면강의/경영과학2/OR2_DESIGNPROJECT/OR_FINAL.R', encoding = 'UTF-8', echo=TRUE)
data_hc_s <- hclust(d=dist(data), method = 'single')
data_hc
plot(data_hc_s, hang=-1)
rect.hclust(data_hc, k=3)
rect.hclust(data_hc_s, k=3)
plot(data_hc_c, hang=-1)
rect.hclust(data_hc_c, k=3)
# Hierarchical clusering
data_hc_c <- hclust(d=dist(data), method = 'complete')
data_hc_c
plot(data_hc_c, hang=-1)
rect.hclust(data_hc_c, k=3)
data_hc_a <- hclust(d=dist(data), method = 'average')
data_hc_a
plot(data_hc_a, hang=-1)
rect.hclust(data_hc_a, k=3)
data_hc_s <- hclust(d=dist(data), method = 'single')
data_hc
v
data_hc_s
plot(data_hc_s, hang=-1)
rect.hclust(data_hc_s, k=3)
data_hc_m <- hclust(d=dist(data), method = 'median')
data_hc_m
plot(data_hc_m, hang=-1)
rect.hclust(data_hc_m, k=3)
data_hc_ct <- hclust(d=dist(data), method = 'centroid')
plot(data_hc_ct, hang=-1)
rect.hclust(data_hc_ct, k=3)
data_hc_w <- hclust(d=dist(data), method = 'ward.D2')
data_hc_w
plot(data_hc_w, hang=-1)
rect.hclust(data_hc_w, k=3)
plot(silhouette(cutree(data_hc_w, k=3), dist=dist(data)))
plot(silhouette(cutree(data_hc_ct, k=3), dist=dist(data)))
plot(silhouette(cutree(data_hc_m, k=3), dist=dist(data)))
plot(silhouette(cutree(data_hc_s, k=3), dist=dist(data)))
plot(silhouette(cutree(data_hc_a, k=3), dist=dist(data)))
plot(silhouette(cutree(data_hc_c, k=3), dist=dist(data)))
# Hierarchical clusering
s_data <- scale(data)
data_hc_c <- hclust(d=dist(s_data), method = 'complete')
data_hc_c
plot(data_hc_c, hang=-1)
rect.hclust(data_hc_c, k=3)
plot(silhouette(cutree(data_hc_c, k=3), dist=dist(s_data)))
data_hc_a <- hclust(d=dist(s_data), method = 'average')
data_hc_a
plot(data_hc_a, hang=-1)
rect.hclust(data_hc_a, k=3)
plot(silhouette(cutree(data_hc_a, k=3), dist=dist(s_data)))
data_hc_s <- hclust(d=dist(s_data), method = 'single')
plot(silhouette(cutree(data_hc_s, k=3), dist=dist(s_data)))
data_hc_m <- hclust(d=dist(s_data), method = 'median')
data_hc_m
plot(data_hc_m, hang=-1)
rect.hclust(data_hc_m, k=3)
plot(silhouette(cutree(data_hc_m, k=3), dist=dist(s_data)))
data_hc_ct <- hclust(d=dist(s_data), method = 'centroid')
data_hc_ct
plot(data_hc_ct, hang=-1)
rect.hclust(data_hc_ct, k=3)
plot(silhouette(cutree(data_hc_ct, k=3), dist=dist(v)))
plot(silhouette(cutree(data_hc_ct, k=3), dist=dist(s_data)))
data_hc_w <- hclust(d=dist(s_data), method = 'ward.D2')
data_hc_w
plot(data_hc_w, hang=-1)
rect.hclust(data_hc_w, k=3)
plot(silhouette(cutree(data_hc_w, k=3), dist=dist(v)))
plot(silhouette(cutree(data_hc_w, k=3), dist=dist(s_data)))
s_data <- scale(data)
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_c <- kmeans(s_data, 3)
data_c
data_c$cluster
data_c$centers
clusplot(data, data_c$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
plot(data_hc_w, hang=-1)
rect.hclust(data_hc_w, k=3)
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_c <- kmeans(s_data, 3)
data_c
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_c <- kmeans(s_data, 3)
data_c
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_c <- kmeans(s_data, 3)
data_c
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_c <- kmeans(s_data, 3)
data_c
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_c <- kmeans(s_data, 3)
data_c
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_c <- kmeans(s_data, 3)
data_c
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_c <- kmeans(s_data, 3)
data_c
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3)
data_c
data_kpp <- kmeanpp(s_data,3)
install.packages("ClusterR")
library(ClusterR)
# optimal_cluster_GMM
op_gmm <- Optimal_Clusters_GMM(s_data,
3,
criterion = "AIC",
dist_mode = "eucl_dist",
seed_mode = "static_spread",
km_iter = 10,
verbose = "FALSE",
plot_data = TRUE,
seed=0)
# optimal_cluster_GMM
op_gmm <- Optimal_Clusters_GMM(s_data,
3,
criterion = "AIC",
dist_mode = "eucl_dist",
seed_mode = "static_spread",
km_iter = 10,
verbose = FALSE,
plot_data = TRUE,
seed=0)
# optimal_cluster_GMM
op_gmm <- Optimal_Clusters_GMM(s_data,
3,
criterion = "AIC",
dist_mode = "eucl_dist",
seed_mode = "static_spread",
km_iter = 10,
verbose = FALSE,
plot_data = FALSE,
seed=0)
op_gmm
# optimal_cluster_GMM
op_gmm <- Optimal_Clusters_GMM(s_data,
3,
criterion = "BIC",
dist_mode = "eucl_dist",
seed_mode = "static_spread",
km_iter = 10,
verbose = FALSE,
plot_data = FALSE,
seed=0)
op_gmm
# optimal_cluster_GMM
op_gmm <- Optimal_Clusters_GMM(s_data,
3,
criterion = "BIC",
dist_mode = "eucl_dist",
seed_mode = "static_spread",
km_iter = 10
)
op_gmm
plot(op_gmm)
# optimal_cluster_GMM
op_gmm <- Optimal_Clusters_GMM(s_data,
3,
criterion = "BIC", # baysian criterion
dist_mode = "eucl_dist", # dist is euclidean
seed_mode = "static_spread", # static sead mode
km_iter = 10, # km iter 10
plot_data = T
)
# optimal_cluster_GMM
op_gmm <- Optimal_Clusters_GMM(s_data,
3,
criterion = "BIC", # baysian criterion
dist_mode = "eucl_dist", # dist is euclidean
seed_mode = "static_spread", # static sead mode
km_iter = 10, # km iter 10
plot_data = TRUE
)
data_kpp <- kmeanpp(s_data,3)
data_kpp <- kmeansPP(s_data,3)
set.seed(10)
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3)
data_c
data_c$cluster
data_c$centers
clusplot(data, data_c$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
table(data_c$cluster)
install.packages("NbClustr")
summary(data_c)
summary(s_data)
data_k
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3)
data_k
clusplot(data, data_c$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3,10)
data_k
summary(data_c)
data_k$cluster
data_k$centers
clusplot(data, data_c$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3, 10)
data_k
clusplot(data, data_c$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
clusplot(data, data_k$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3)
clusplot(data, data_k$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
data_k
plot(silhouette(cutree(data_hc_w, k=3), dist=dist(s_data)))
plot(data_hc_w, hang=-1)
rect.hclust(data_hc_w, k=3)
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3, iter.max = 10)
data_k
clusplot(data, data_k$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3, iter.max = 10, iter.min=10)
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3, iter.max = 10)
clusplot(data, data_k$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3, iter.max = 9)
clusplot(data, data_k$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
data_k
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3, iter.max = 5)
data_k
clusplot(data, data_k$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3, iter.max = 8)
data_k
clusplot(data, data_k$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3, iter.max = 9)
clusplot(data, data_k$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
data_k
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3, iter.max = 10)
clusplot(data, data_k$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
data_k
data_k
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3, iter.max = 30)
data_k
clusplot(data, data_k$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3, iter.max = 10)
data_k
clusplot(data, data_k$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3, iter.max = 10)
clusplot(data, data_k$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
data_k
library(NbClust)
install.packages("NbClust")
install.packages("NbClust")
# install.packages("NbClust")
library(NbClust)
library(magrittr)
library(ggplot2)
# k means same size
data_ss <- s_data
data_ss %>% kmeans(k) -> kclust
kdist = function(x1,y1,x2,y2){
sqrt((x1-x2)^2 + (y1-y2)^2)
}
# k means same size
data_ss <- s_data
k = 3
data_ss %>% kmeans(k) -> kclust
kdist = function(x1,y1,x2,y2){
sqrt((x1-x2)^2 + (y1-y2)^2)
}
centers = kclust$centers
data_ss %<>% mutate(D1=kdist(data_ss[], centers[1,1], centers[1,2]))
data_ss %<>% mutate(D1=kdist(data_ss[,], centers[1,1], centers[1,2]))
data_ss %<>% mutate(D1=kdist(data_ss, centers[1,1], centers[1,2]))
data_ss %<>% mutate(D1=kdist(data_ss[-1], centers[1,1], centers[1,2]))
set.seed(0)
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3, iter.max = 10)
data_k
summary(data_c)
data_k$cluster
data_k$centers
clusplot(data, data_k$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3)
data_k
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3, iter.max = 10)
data_k
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3, iter.max = 9)
data_k
clusplot(data, data_k$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3, iter.max = 9, nstart = 10)
data_k
summary(data_c)
data_k$cluster
data_k$centers
clusplot(data, data_k$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3, iter.max = 9)
data_k
summary(data_c)
data_k$cluster
data_k$centers
clusplot(data, data_k$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3, iter.max = 9)
data_k
summary(data_c)
data_k$cluster
data_k$centers
clusplot(data, data_k$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
data_d <- dbscan(data, eps=3.5, MinPts=10)
table(data_d$cluster)
plot(silhouette(cutree(data_hc_a, k=3), dist=dist(s_data)))
data_hc_s <- hclust(d=dist(s_data), method = 'single')
rect.hclust(data_hc_a, k=3)
plot(data_hc_a, hang=-1)
rect.hclust(data_hc_a, k=3)
rect.hclust(data_hc_c, k=3)
plot(silhouette(cutree(data_hc_c, k=3), dist=dist(s_data)))
plot(data_hc_c, hang=-1)
rect.hclust(data_hc_c, k=3)
# optimal_cluster_GMM
op_gmm <- Optimal_Clusters_GMM(s_data,
3,
criterion = "BIC", # baysian criterion
dist_mode = "eucl_dist", # dist is euclidean
seed_mode = "static_spread", # static sead mode
km_iter = 10, # km iter 10
plot_data = TRUE
)
op_gmm
cor.test(data)
cor(data)
co <_ cor(data)
co <- cor(data)
View(co)
summary(data)
# k medizn
pam(s_data, 3, metric = "euclidean", stand = FALSE)
# k medizn
data_p <- pam(s_data, 3, metric = "euclidean", stand = FALSE)
clusplot(s_data, data_p$clustering, color=FALSE, shade = FALSE,
labels = 3, lines = 0)
clusplot(s_data, data_p$clustering, color=FALSE, shade = TRUE,
labels = 3, lines = 0)
clusplot(data, data_k$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3)
clusplot(data, data_k$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3, iter.max = 10)
clusplot(data, data_k$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3, iter.max = 9)
clusplot(data, data_k$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
# k means
# cluster가 7, 13, 10 또는 10, 8, 12로 묶임
data_k <- kmeans(s_data, 3, iter.max = 9)
clusplot(data, data_k$cluster, color = TRUE, shade = TRUE,
labels = 3, lines = 0)
data_k
# Hierarchical clusering
data_hc_c <- hclust(d=dist(s_data), method = 'complete')
plot(data_hc_c, hang=-1)
rect.hclust(data_hc_c, k=3)
plot(data_hc_ct, hang=-1)
rect.hclust(data_hc_ct, k=3)
plot(data_hc_w, hang=-1)
rect.hclust(data_hc_w, k=3)
# optimal_cluster_GMM
op_gmm <- Optimal_Clusters_GMM(s_data,
3,
criterion = "BIC", # baysian criterion
dist_mode = "eucl_dist", # dist is euclidean
seed_mode = "static_spread", # static sead mode
km_iter = 10, # km iter 10
plot_data = TRUE
)
